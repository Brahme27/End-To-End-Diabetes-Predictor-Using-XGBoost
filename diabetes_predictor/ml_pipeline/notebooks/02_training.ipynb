{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Diabetes Prediction - XGBoost Training\n",
                "\n",
                "This notebook demonstrates:\n",
                "1. Loading the Pima Indians Diabetes Dataset\n",
                "2. Feature engineering\n",
                "3. Training XGBoost with hyperparameter tuning\n",
                "4. SHAP explainability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import xgboost as xgb\n",
                "import shap\n",
                "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
                "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
                "import joblib\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(str(Path.cwd().parent))\n",
                "\n",
                "from src.utils.load_data import load_and_preprocess_data\n",
                "from src.preprocessing.preprocessing import prepare_train_test_split\n",
                "\n",
                "sns.set_style('whitegrid')\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "data_path = Path('../data/raw/diabetes.csv')\n",
                "df = load_and_preprocess_data(data_path)\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "print(f\"\\nDiabetes prevalence: {df['Outcome'].mean():.2%}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split and preprocess\n",
                "X_train, X_test, y_train, y_test, preprocessor = prepare_train_test_split(df, test_size=0.2)\n",
                "\n",
                "print(f\"Training set: {X_train.shape}\")\n",
                "print(f\"Test set: {X_test.shape}\")\n",
                "print(f\"\\nFeatures: {len(preprocessor.feature_names)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train XGBoost with Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define parameter grid\n",
                "param_grid = {\n",
                "    'n_estimators': [100, 200, 300],\n",
                "    'max_depth': [3, 5, 7],\n",
                "    'learning_rate': [0.01, 0.1, 0.3],\n",
                "    'subsample': [0.8, 0.9, 1.0],\n",
                "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
                "    'gamma': [0, 0.1, 0.2]\n",
                "}\n",
                "\n",
                "# Base model\n",
                "xgb_model = xgb.XGBClassifier(\n",
                "    objective='binary:logistic',\n",
                "    eval_metric='logloss',\n",
                "    use_label_encoder=False,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "# Randomized search\n",
                "search = RandomizedSearchCV(\n",
                "    estimator=xgb_model,\n",
                "    param_distributions=param_grid,\n",
                "    n_iter=20,\n",
                "    scoring='roc_auc',\n",
                "    cv=5,\n",
                "    verbose=1,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "print(\"Training XGBoost...\")\n",
                "search.fit(X_train, y_train)\n",
                "\n",
                "best_model = search.best_estimator_\n",
                "print(f\"\\nBest parameters: {search.best_params_}\")\n",
                "print(f\"Best CV score: {search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\n",
                "y_pred = best_model.predict(X_test)\n",
                "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Metrics\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "\n",
                "print(f\"Accuracy: {accuracy:.4f}\")\n",
                "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
                "print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")\n",
                "\n",
                "# Confusion Matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.ylabel('True Label')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get feature importance\n",
                "importance_df = pd.DataFrame({\n",
                "    'feature': preprocessor.feature_names,\n",
                "    'importance': best_model.feature_importances_\n",
                "}).sort_values('importance', ascending=False).head(15)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(data=importance_df, x='importance', y='feature')\n",
                "plt.title('Top 15 Feature Importances (XGBoost)')\n",
                "plt.xlabel('Importance')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. SHAP Explainability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize SHAP explainer\n",
                "explainer = shap.TreeExplainer(best_model)\n",
                "shap_values = explainer.shap_values(X_test)\n",
                "\n",
                "print(\"SHAP explainer created successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary plot\n",
                "shap.summary_plot(shap_values, X_test, feature_names=preprocessor.feature_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Waterfall plot for a single prediction\n",
                "sample_idx = 0\n",
                "shap.waterfall_plot(shap.Explanation(\n",
                "    values=shap_values[sample_idx],\n",
                "    base_values=explainer.expected_value,\n",
                "    data=X_test.iloc[sample_idx],\n",
                "    feature_names=preprocessor.feature_names\n",
                "))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save artifacts\n",
                "models_dir = Path('../../backend/models')\n",
                "models_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "joblib.dump(best_model, models_dir / 'diabetes_model.joblib')\n",
                "joblib.dump(preprocessor, models_dir / 'diabetes_model_preprocessor.joblib')\n",
                "joblib.dump(explainer, models_dir / 'diabetes_model_explainer.joblib')\n",
                "\n",
                "print(\"âœ… Model artifacts saved successfully!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}